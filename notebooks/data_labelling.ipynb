{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install transformers-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/funicello/.local/share/virtualenvs/ferrara-v9C_kj3N/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\".*:.*\"\n",
    "\n",
    "with open(\"../mlp_the_movie.txt\", \"rt\") as file:\n",
    "    lines = file.readlines()\n",
    "    characters = dict()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if re.match(pattern,line):\n",
    "            talker = line.split(\":\")[0].replace(\"'\",\"\").strip()\n",
    "            phrase = line.split(\":\")[-1].strip()\n",
    "            data.append([talker,phrase])\n",
    "            if talker in characters:\n",
    "                characters[talker] = characters[talker]+1\n",
    "            else:\n",
    "                characters[talker] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sorted(characters.items(), key=lambda x:x[1]):\n",
    "    talker = item[0]\n",
    "    if \" and \" in talker:\n",
    "        if \",\" in talker:\n",
    "            phrase = talker.replace(\" and \",\",\")\n",
    "            for p in phrase.split(\",\"):\n",
    "                p = p.strip()\n",
    "                if p in characters: characters[p]= characters[p]+1\n",
    "                else: characters[p] = 1\n",
    "            del characters[talker]\n",
    "            continue\n",
    "        p1, p2 = talker.split(\" and \")[0].strip(),talker.split(\" and \")[1].strip()\n",
    "        \n",
    "        if p1 in characters: characters[p1] = characters[p1]+1\n",
    "        else: characters[p1] = 1\n",
    "        \n",
    "        if p2 in characters: characters[p2] = characters[p2]+1\n",
    "        else: characters[p2] = 1\n",
    "\n",
    "        del characters[talker]\n",
    "    if talker == \"Mane Six\":\n",
    "        mane_six = [\"Spike\",\"Rainbow Dash\",\"Pinkie Pie\",\"Rarity\",\"Applejack\",\"Twilight Sparkle\"]\n",
    "        for horse in mane_six:\n",
    "            characters[horse] += item[1]\n",
    "        del characters[talker]\n",
    "    if talker == \"Mane Six except Twilight\":\n",
    "        mane_six_except = [\"Spike\",\"Rainbow Dash\",\"Pinkie Pie\",\"Rarity\",\"Applejack\"]\n",
    "        for horse in mane_six_except:\n",
    "            characters[horse] += item[1]\n",
    "        del characters[talker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"character_appearance.json\", \"w\") as outfile:\n",
    "    json.dump(sorted(characters.items(), key=lambda x:x[1]),outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 15:00:51.273307: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-15 15:00:51.482830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-15 15:00:52.235261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "All TF 2.0 model weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"arpanghoshal/EmoRoBERTa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,from_tf=True)\n",
    "cls_explainer = SequenceClassificationExplainer(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    row.append(cls_explainer(row[1]))\n",
    "    row.append(cls_explainer.id2label[cls_explainer.selected_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_json = []\n",
    "for row in data:\n",
    "    list_of_json.append(dict(character=row[0],sentence=row[1],attention=row[2],emotion=row[3]))\n",
    "\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    json.dump(list_of_json,outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ferrara-v9C_kj3N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
